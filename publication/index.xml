<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>publications | Mingkun&#39;s homepage</title>
    <link>https://mingkunyang.github.io/publication/</link>
      <atom:link href="https://mingkunyang.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>publications</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Dec 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mingkunyang.github.io/images/icon_hu786fa58ccadddb09b05070c28e40422f_10189_512x512_fill_lanczos_center_2.png</url>
      <title>publications</title>
      <link>https://mingkunyang.github.io/publication/</link>
    </image>
    
    <item>
      <title>LightVO: Lightweight Inertial-Assisted Monocular Visual Odometry with Dense Neural Networks</title>
      <link>https://mingkunyang.github.io/publication/globecom/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://mingkunyang.github.io/publication/globecom/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Visual Odometry (VO), conducts the ego-motion estimation using on-board camera. In this paper, a &lt;strong&gt;learning-based monocular VO&lt;/strong&gt; is proposed. What&amp;rsquo;s more, with the IMU correction through &lt;strong&gt;loose-coupled mechanism&lt;/strong&gt;, a visual-inertial odometry improves the accuracy of pose estimation further.&lt;/p&gt;
&lt;h2 id=&#34;contribution&#34;&gt;&lt;strong&gt;Contribution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The input of the proposed VO is optical flow extracted by TVNet, and the structure of the learning-based VO is inspired by the DenseNet that is lightweight and effective neural network mainly applied to CV feilds. Utilizing the &lt;strong&gt;KF&lt;/strong&gt;, the inertial positioning is merged into the navigation scheme. The contributions can be summarized into:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Lightweight and accurate visual odometry&lt;/strong&gt;: Both parameters amount and average execution time of the proposed VO is lighter than competing approach. In addation, the proposed VO outperforms other VO in translation estimation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loose-coupled visual-inertial odometry&lt;/strong&gt;: The well devisd data fusion algorithm considers the accumulated error of INS. Therefore, the &lt;strong&gt;penalty for translation estimation&lt;/strong&gt; by INS is set, which avoids excessive correction. Compared with the proposed visual odometry, the visual-inertial decreases the translation and rotation error by up to &lt;strong&gt;70%&lt;/strong&gt; and &lt;strong&gt;73%&lt;/strong&gt;, respectively.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficient Human Activity Recognition Solving the Confusing Activities via Deep Ensemble Learning</title>
      <link>https://mingkunyang.github.io/publication/access/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://mingkunyang.github.io/publication/access/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Human activity recognition (HAR), &lt;strong&gt;identifying the actions of individual&lt;/strong&gt; based on a set of observation, is widely applied to pedestrian indoor tracking, healthcare, Intelligent city, etc. Vision-based recognition algorithms suffer from factors such as lighting condition, clothing color, and image background. Therefore, this paper, leveraging the &lt;strong&gt;build-in sensor of the smartphone&lt;/strong&gt;, proposes a sensor-based HAR model.&lt;/p&gt;
&lt;h2 id=&#34;contribution&#34;&gt;&lt;strong&gt;Contribution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The proposed model utilizes CNN to perform the HAR task. A CNN-7 block is used to identify seven activities. In terms of confusing human activities, a binary-classifier CNN-2, in the &lt;strong&gt;ensemble learning&lt;/strong&gt; way, helps the model to determine the actual human activity through &lt;strong&gt;weighted voting&lt;/strong&gt;. The contributions can be summarized into:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Abundant and extensive date collection&lt;/strong&gt;: The data in this paper contains three motion sensors readings collected by 100 participants. There are &lt;strong&gt;four different placements&lt;/strong&gt; of the smartphone and &lt;strong&gt;seven typical daily human activities&lt;/strong&gt;. The data set not only guarantees the effective training on neural network, but makes the recognition task challenging.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accurate and robust recognition&lt;/strong&gt;: &lt;strong&gt;Avoiding handcrafted features engineering&lt;/strong&gt;, the average accuracy of proposed ensemble model can achieve up to &lt;strong&gt;96.11%&lt;/strong&gt;. The devised voting mechanism &lt;strong&gt;improves the classification accuracy among two confusing activities&lt;/strong&gt; (walking and going upstairs) further.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The Research of Stance-Phase Detection to Improve ZUPT-Aided Pedestrian Navigation System</title>
      <link>https://mingkunyang.github.io/publication/iscas/</link>
      <pubDate>Wed, 01 May 2019 00:00:00 +0000</pubDate>
      <guid>https://mingkunyang.github.io/publication/iscas/</guid>
      <description>&lt;h2 id=&#34;background&#34;&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In the &lt;strong&gt;GPS-denied&lt;/strong&gt; environment, inertial navigation system is the justifiable and general solution because it &lt;strong&gt;do not require installation of infrastructure beforehand&lt;/strong&gt;. Nevertheless, the inertial navigation system (INS) calculates the relative displacement of an object that will result in &lt;strong&gt;accumulated errors&lt;/strong&gt; due to the sensorsâ€™ drift. Under the assumption that the velocity is zero when foot is on the ground, ZUPT-aided INS modify the positioning error leveraging this pseudo-measurement.&lt;/p&gt;
&lt;h2 id=&#34;contribution&#34;&gt;&lt;strong&gt;Contribution&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This paper improve the ZUPT-aided INS in two aspects: 1) By considering the zero velocity detecion as a hypothesis-testing problem, we propose a new test statistic; 2) To avoid excessive modification of heading angle (yaw), an asymptotic ZUPT is devised.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Accurate zero velocity detection&lt;/strong&gt;: This paper takes the &lt;strong&gt;difference value&lt;/strong&gt; of gyroscope as the test statistic, which makes the wave more sharper. The proposed method enable zero velocity detecion to maintain its accuracy &lt;strong&gt;in high-dynamic motion&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stable attitude modification&lt;/strong&gt;: The heading angle, with zero velocity update, is prone to deviation, because the excessive yaw error estimation by KF at the initial update. Therefore, the &lt;strong&gt;attenuation factor&lt;/strong&gt; is applied to the pseudo-measurement, which alleviates the yaw fluctuation after update.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
